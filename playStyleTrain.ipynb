{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H36Op8UfQhcy",
        "outputId": "db324112-49bd-49f5-e9b4-65c05f6cdcda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# 連接雲端硬碟(訓練資料存在雲端)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0RTvasTSXbn4"
      },
      "outputs": [],
      "source": [
        "def search(all, target, row, column, visited, live):\n",
        "    visited.add((row, column))\n",
        "    directions = [(0, -1), (0, 1), (-1, 0), (1, 0)]  # Up, down, left, right\n",
        "    for dr, dc in directions:\n",
        "        r, c = row + dr, column + dc\n",
        "        if 0 <= r <= 18 and 0 <= c <= 18 and (r, c) not in visited:\n",
        "            if all[r][c] == 0 and target[r][c] == 0:\n",
        "                return True\n",
        "            elif target[r][c] == 1:\n",
        "                live = search(all, target, r, c, visited, live)\n",
        "                if live:\n",
        "                    return live\n",
        "    return False\n",
        "\n",
        "def dieCheck(all, target, row, column):\n",
        "    num = 4\n",
        "    directions = [(0, -1), (0, 1), (-1, 0), (1, 0)]  # Up, down, left, right\n",
        "    for dr, dc in directions:\n",
        "        r, c = row + dr, column + dc\n",
        "        if r < 0 or r > 18 or c < 0 or c > 18 or all[r][c] == 1:\n",
        "            num -= 1\n",
        "    if num == 0:\n",
        "        target[row][column] = 0\n",
        "        return target\n",
        "    else:\n",
        "        num -= sum(target[row + dr][column + dc] == 1 for dr, dc in directions if 0 <= row + dr <= 18 and 0 <= column + dc <= 18)\n",
        "        if num == 0:\n",
        "            live = False\n",
        "            visited = set()\n",
        "            for dr, dc in directions:\n",
        "                r, c = row + dr, column + dc\n",
        "                if 0 <= r <= 18 and 0 <= c <= 18 and target[r][c] == 1 and (r, c) not in visited:\n",
        "                    live = search(all, target, r, c, visited, live)\n",
        "                    if live:\n",
        "                        break\n",
        "            if not live:\n",
        "                for r, c in visited:\n",
        "                    target[r][c] = 0\n",
        "    return target\n",
        "\n",
        "def twoColor(moves, previous_board=None):\n",
        "    if previous_board is None:\n",
        "        blackAll = np.zeros((19,19))\n",
        "        whiteAll = np.zeros((19,19))\n",
        "    else:\n",
        "        blackAll, whiteAll = previous_board\n",
        "        moves = [moves[-1]]\n",
        "\n",
        "    for i in moves:\n",
        "        column = int(i[2:4])\n",
        "        row = int(i[4:6])\n",
        "        color = i[0]\n",
        "        if color == 'B':\n",
        "            blackAll[row][column] = 1\n",
        "            target = whiteAll\n",
        "            all = blackAll\n",
        "        else:\n",
        "            whiteAll[row][column] = 1\n",
        "            target = blackAll\n",
        "            all = whiteAll\n",
        "\n",
        "        arr = [0, 0, 0, 0]\n",
        "        if row > 0 and target[row-1][column] == 1:\n",
        "            arr[0] = 1\n",
        "        if row < 18 and target[row+1][column] == 1:\n",
        "            arr[1] = 1\n",
        "        if column > 0 and target[row][column-1] == 1:\n",
        "            arr[2] = 1\n",
        "        if column < 18 and target[row][column+1] == 1:\n",
        "            arr[3] = 1\n",
        "\n",
        "        for i in range(4):\n",
        "            if arr[i]==1:\n",
        "                if i==0:\n",
        "                    target = dieCheck(all, target=target, row=row-1, column=column)\n",
        "                elif i==1:\n",
        "                    target = dieCheck(all, target=target, row=row+1, column=column)\n",
        "                elif i==2:\n",
        "                    target = dieCheck(all, target=target, row=row, column=column-1)\n",
        "                elif i==3:\n",
        "                    target = dieCheck(all, target=target, row=row, column=column+1)\n",
        "\n",
        "        if color == 'B':\n",
        "            whiteAll = target\n",
        "        else:\n",
        "            blackAll = target\n",
        "\n",
        "    return blackAll, whiteAll\n",
        "\n",
        "def liberties(board):\n",
        "    liberties_board = np.zeros((19,19))\n",
        "    directions = [(0, -1), (0, 1), (-1, 0), (1, 0)]  # Up, down, left, right\n",
        "    visited = set()\n",
        "    liberties_visited = set()\n",
        "\n",
        "    for row in range(19):\n",
        "        for column in range(19):\n",
        "            if board[row][column] != 0 and (row, column) not in visited:  # If there is a stone at this position\n",
        "                group = [(row, column)]\n",
        "                liberties_count = 0\n",
        "                liberties_visited.clear()\n",
        "                visited.add((row, column))\n",
        "\n",
        "                # Find all stones in the same group\n",
        "                i = 0\n",
        "                while i < len(group):\n",
        "                    r, c = group[i]\n",
        "                    for dr, dc in directions:\n",
        "                        nr, nc = r + dr, c + dc\n",
        "                        if 0 <= nr <= 18 and 0 <= nc <= 18:\n",
        "                            if board[nr][nc] == 0 and (nr, nc) not in liberties_visited:  # If the adjacent position is empty\n",
        "                                liberties_count += 1\n",
        "                                liberties_visited.add((nr, nc))\n",
        "                            elif board[nr][nc] == board[row][column] and (nr, nc) not in visited:  # If the adjacent stone is the same color\n",
        "                                group.append((nr, nc))\n",
        "                                visited.add((nr, nc))\n",
        "                    i += 1\n",
        "\n",
        "                # Assign the liberties count to all stones in the same group\n",
        "                for r, c in group:\n",
        "                    liberties_board[r][c] = liberties_count\n",
        "    return liberties_board"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZZa1u8lMEKk",
        "outputId": "40692ee7-a138-4a4b-dfbe-7dcc5874edcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Games: 26615\n",
            "(23953, 3) (2662, 3)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, ReLU, Flatten, Dense, Softmax, BatchNormalization, Dropout, Add\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = open('/content/drive/MyDrive/play_style_train.csv').read().splitlines()\n",
        "games = [i.split(',',2)[-1] for i in df]\n",
        "game_styles = [int(i.split(',',2)[-2]) for i in df]\n",
        "\n",
        "chars = 'abcdefghijklmnopqrs'\n",
        "coordinates = {k:v for v,k in enumerate(chars)}\n",
        "\n",
        "def prepare_input(moves):\n",
        "\n",
        "    array = np.zeros((19,19,8))\n",
        "\n",
        "    target_step = len(moves)\n",
        "    # 前兩步\n",
        "    if target_step > 2:\n",
        "        array[:,:,0], array[:,:,1] = twoColor(moves[:target_step - 2])\n",
        "    # 前一步\n",
        "    if target_step > 1:\n",
        "        array[:,:,2], array[:,:,3] = twoColor([moves[target_step - 2]], previous_board=(array[:,:,0], array[:,:,1]))\n",
        "    # 目前這一步\n",
        "    array[:,:,4], array[:,:,5] = twoColor([moves[target_step - 1]], previous_board=(array[:,:,2], array[:,:,3]))\n",
        "\n",
        "    # 計算氣\n",
        "    array[:,:,6] = liberties(array[:,:,4] + array[:,:,5] * 2) / 10\n",
        "\n",
        "    target_col = int(moves[-1][2:4])\n",
        "    target_row = int(moves[-1][4:6])\n",
        "\n",
        "    # 單獨最後一步\n",
        "    array[target_row, target_col,7] = 1\n",
        "\n",
        "    return array\n",
        "\n",
        "# Check 有多少局資料\n",
        "n_games = 0\n",
        "for game in games:\n",
        "    n_games += 1\n",
        "print(f\"Total Games: {n_games}\")\n",
        "\n",
        "x = []\n",
        "for game in games:\n",
        "    for char in chars:\n",
        "        if (len(str(coordinates[char])) == 1):\n",
        "            num = '0' + str(coordinates[char])\n",
        "        else:\n",
        "            num = str(coordinates[char])\n",
        "        game = game.replace(char, num)\n",
        "    moves_list = game.split(',')\n",
        "    x.append(prepare_input(moves_list))\n",
        "x = np.array(x)\n",
        "y = np.array(game_styles)-1\n",
        "\n",
        "y_hot = tf.one_hot(y, depth=3)\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x, y_hot.numpy(), test_size=0.10)\n",
        "print(y_train.shape, y_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4Vt9W6jVq2q",
        "outputId": "06bacc6a-ecba-476c-f9c0-22d42f965c2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 19, 19, 8)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 19, 19, 64)        4672      \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 19, 19, 64)        256       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " activation (Activation)     (None, 19, 19, 64)        0         \n",
            "                                                                 \n",
            " sequential (Sequential)     (None, 19, 19, 64)        148736    \n",
            "                                                                 \n",
            " sequential_1 (Sequential)   (None, 19, 19, 64)        157056    \n",
            "                                                                 \n",
            " sequential_4 (Sequential)   (None, 19, 19, 128)       543488    \n",
            "                                                                 \n",
            " average_pooling2d (Average  (None, 9, 9, 128)         0         \n",
            " Pooling2D)                                                      \n",
            "                                                                 \n",
            " sequential_7 (Sequential)   (None, 9, 9, 128)         625408    \n",
            "                                                                 \n",
            " average_pooling2d_1 (Avera  (None, 4, 4, 128)         0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " batch_normalization_17 (Ba  (None, 2048)              8192      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               524544    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 771       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2013123 (7.68 MB)\n",
            "Trainable params: 2005827 (7.65 MB)\n",
            "Non-trainable params: 7296 (28.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# 建立residual layer的class\n",
        "class basicBlock(keras.layers.Layer):\n",
        "\n",
        "    # kernel_size卷積層大小預設為3，stride為1，filter_num代表輸出多少層filter\n",
        "    # 如果經過卷積層的filter_num跟原始輸入的filter_num不一樣，下面self.downsample.add會error。\n",
        "    # 將change = True讓filter_num保持一致\n",
        "    def __init__(self, filter_num, stride=1, change=False, kernel_size=3):\n",
        "        super(basicBlock, self).__init__()\n",
        "\n",
        "        # 內含兩個卷積層\n",
        "        # padding='same'讓輸出維持19*19*X\n",
        "        # 卷積層1\n",
        "        self.conv1 = keras.layers.Conv2D(filter_num, kernel_size=kernel_size, strides=stride, padding='same')\n",
        "\n",
        "        self.bn1 = keras.layers.BatchNormalization()\n",
        "        self.relu = keras.layers.Activation('relu')\n",
        "\n",
        "        # 卷積層2\n",
        "        self.conv2 = keras.layers.Conv2D(filter_num, kernel_size=kernel_size, strides=stride, padding='same')\n",
        "        self.bn2 = keras.layers.BatchNormalization()\n",
        "\n",
        "        # 未經過卷積層的input\n",
        "        if change != False:\n",
        "            self.downsample = keras.Sequential()\n",
        "            self.downsample.add(keras.layers.Conv2D(filter_num, kernel_size=1, strides=stride, padding='same'))\n",
        "        else:\n",
        "            self.downsample = lambda x: x\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "\n",
        "        #前向計算forward\n",
        "        out = self.conv1(inputs)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        #inputs通過identity轉換\n",
        "        identity = self.downsample(inputs)\n",
        "\n",
        "        # f(x)+x運算\n",
        "        output = keras.layers.add([out, identity])\n",
        "\n",
        "        # 再通過relu激活函數並回傳\n",
        "        output = tf.nn.relu(output)\n",
        "        return output\n",
        "\n",
        "# 多個residual layer組成的block\n",
        "def build_resblock(filter_num, blocks, stride=1, change=False, kernel=3):\n",
        "    Resblock = keras.Sequential()\n",
        "    Resblock.add(basicBlock(filter_num=filter_num, stride=stride, change=change, kernel_size=kernel))\n",
        "\n",
        "    #第一個之後的residual layer的stride固定是1\n",
        "    for i in range(1, blocks):\n",
        "        Resblock.add(basicBlock(filter_num=filter_num, stride=1, change=change, kernel_size=kernel))\n",
        "    return Resblock\n",
        "\n",
        "# 建模型\n",
        "def create_model():\n",
        "    inputs = keras.layers.Input(shape=(19, 19, 8))\n",
        "    outputs = keras.layers.Conv2D(kernel_size=3, filters=64, strides=1, padding='same')(inputs)\n",
        "    outputs = keras.layers.BatchNormalization()(outputs)\n",
        "    outputs = keras.layers.Activation('relu')(outputs)\n",
        "\n",
        "    outputs = build_resblock(filter_num=64, blocks=2, kernel=3)(outputs)\n",
        "    outputs = build_resblock(filter_num=64, blocks=2, stride=1, change=True, kernel=3)(outputs)\n",
        "    outputs = build_resblock(filter_num=128, blocks=2, stride=1, change=True, kernel=3)(outputs)\n",
        "    outputs = keras.layers.AveragePooling2D(pool_size=(2,2))(outputs)\n",
        "    outputs = build_resblock(filter_num=128, blocks=2, stride=1, change=True, kernel=3)(outputs)\n",
        "    outputs = keras.layers.AveragePooling2D(pool_size=(2,2))(outputs)\n",
        "\n",
        "    # 全連接層\n",
        "    outputs = keras.layers.Flatten()(outputs)\n",
        "    outputs = keras.layers.BatchNormalization()(outputs)\n",
        "    outputs = keras.layers.Dense(256, activation='relu')(outputs)\n",
        "    outputs = keras.layers.Dense(3, activation='softmax')(outputs)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs, outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "model = create_model()\n",
        "\n",
        "# 設定optimizer，learning rate=0.001\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o0rIvMaPwNx8",
        "outputId": "ebdf8b5a-0a37-4519-a8e6-f18b7c40a4ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------epoch 1  (LR: 1.000000e-03)-----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7c71b010e3b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7c71b010e3b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 1.0769071578979492\n",
            "accuracy: 0.37890625\n",
            "val loss: 1.0772584676742554\n",
            "val accuracy: 0.39631855487823486\n",
            "weight saved\n",
            "-----------epoch 2  (LR: 1.000000e-03)-----------\n",
            "loss: 1.0690579414367676\n",
            "accuracy: 0.357421875\n",
            "val loss: 1.0701448917388916\n",
            "val accuracy: 0.40533432364463806\n",
            "weight saved\n",
            "-----------epoch 3  (LR: 1.000000e-03)-----------\n",
            "loss: 0.9140371680259705\n",
            "accuracy: 0.55859375\n",
            "val loss: 0.9473146796226501\n",
            "val accuracy: 0.5454545617103577\n",
            "weight saved\n",
            "-----------epoch 4  (LR: 1.000000e-03)-----------\n",
            "loss: 0.8929985165596008\n",
            "accuracy: 0.587890625\n",
            "val loss: 0.9123886227607727\n",
            "val accuracy: 0.5882794857025146\n",
            "weight saved\n",
            "-----------epoch 5  (LR: 1.000000e-03)-----------\n",
            "loss: 0.9204666018486023\n",
            "accuracy: 0.58984375\n",
            "val loss: 0.9261883497238159\n",
            "val accuracy: 0.5800150036811829\n",
            "weight saved\n",
            "-----------epoch 6  (LR: 1.000000e-03)-----------\n",
            "loss: 0.8252468705177307\n",
            "accuracy: 0.673828125\n",
            "val loss: 0.832013726234436\n",
            "val accuracy: 0.6401202082633972\n",
            "weight saved\n",
            "-----------epoch 7  (LR: 1.000000e-03)-----------\n",
            "loss: 0.7939801812171936\n",
            "accuracy: 0.6640625\n",
            "val loss: 0.8188064098358154\n",
            "val accuracy: 0.6558977961540222\n",
            "weight saved\n",
            "-----------epoch 8  (LR: 1.000000e-03)-----------\n",
            "loss: 0.802090585231781\n",
            "accuracy: 0.6484375\n",
            "val loss: 0.78291255235672\n",
            "val accuracy: 0.6739293932914734\n",
            "weight saved\n",
            "-----------epoch 9  (LR: 1.000000e-03)-----------\n",
            "loss: 0.7406362295150757\n",
            "accuracy: 0.70703125\n",
            "val loss: 0.760758101940155\n",
            "val accuracy: 0.6795642375946045\n",
            "weight saved\n",
            "-----------epoch 10  (LR: 1.000000e-03)-----------\n",
            "loss: 0.7761613130569458\n",
            "accuracy: 0.673828125\n",
            "val loss: 0.7910416722297668\n",
            "val accuracy: 0.6697971224784851\n",
            "weight saved\n",
            "-----------epoch 11  (LR: 1.000000e-03)-----------\n",
            "loss: 0.6893640160560608\n",
            "accuracy: 0.72265625\n",
            "val loss: 0.7485517859458923\n",
            "val accuracy: 0.687453031539917\n",
            "weight saved\n",
            "-----------epoch 12  (LR: 1.000000e-03)-----------\n",
            "loss: 0.7786617279052734\n",
            "accuracy: 0.673828125\n",
            "val loss: 0.731320858001709\n",
            "val accuracy: 0.6983470916748047\n",
            "weight saved\n",
            "-----------epoch 13  (LR: 1.000000e-03)-----------\n",
            "loss: 0.7540842890739441\n",
            "accuracy: 0.693359375\n",
            "val loss: 0.7411801815032959\n",
            "val accuracy: 0.6934635639190674\n",
            "-----------epoch 14  (LR: 1.000000e-03)-----------\n",
            "loss: 0.6847246885299683\n",
            "accuracy: 0.734375\n",
            "val loss: 0.7437989115715027\n",
            "val accuracy: 0.6930878758430481\n",
            "-----------epoch 15  (LR: 1.000000e-03)-----------\n",
            "loss: 0.689633309841156\n",
            "accuracy: 0.72265625\n",
            "val loss: 0.734419584274292\n",
            "val accuracy: 0.7066115736961365\n",
            "weight saved\n",
            "weight saved\n",
            "-----------epoch 16  (LR: 1.000000e-03)-----------\n",
            "loss: 0.5997521877288818\n",
            "accuracy: 0.775390625\n",
            "val loss: 0.7371828556060791\n",
            "val accuracy: 0.6908339858055115\n",
            "-----------epoch 17  (LR: 1.000000e-03)-----------\n",
            "loss: 0.6452539563179016\n",
            "accuracy: 0.73046875\n",
            "val loss: 0.7234209179878235\n",
            "val accuracy: 0.6930878758430481\n",
            "-----------epoch 18  (LR: 1.000000e-03)-----------\n",
            "loss: 0.6886046528816223\n",
            "accuracy: 0.720703125\n",
            "val loss: 0.7136572003364563\n",
            "val accuracy: 0.7088655233383179\n",
            "weight saved\n",
            "-----------epoch 19  (LR: 1.000000e-03)-----------\n",
            "loss: 0.7044593095779419\n",
            "accuracy: 0.708984375\n",
            "val loss: 0.7224000096321106\n",
            "val accuracy: 0.7137490510940552\n",
            "weight saved\n",
            "-----------epoch 20  (LR: 1.000000e-03)-----------\n",
            "loss: 0.6677441596984863\n",
            "accuracy: 0.75\n",
            "val loss: 0.7051040530204773\n",
            "val accuracy: 0.7160030007362366\n",
            "weight saved\n",
            "weight saved\n",
            "-----------epoch 21  (LR: 1.000000e-03)-----------\n",
            "loss: 0.6635379791259766\n",
            "accuracy: 0.73828125\n",
            "val loss: 0.7084512710571289\n",
            "val accuracy: 0.7084898352622986\n",
            "-----------epoch 22  (LR: 1.000000e-03)-----------\n",
            "loss: 0.659118115901947\n",
            "accuracy: 0.74609375\n",
            "val loss: 0.7099328637123108\n",
            "val accuracy: 0.71074378490448\n",
            "-----------epoch 23  (LR: 1.000000e-03)-----------\n",
            "loss: 0.6462434530258179\n",
            "accuracy: 0.73828125\n",
            "val loss: 0.7376783490180969\n",
            "val accuracy: 0.7081142067909241\n",
            "learning rate reduced to 5.000000e-04\n",
            "-----------epoch 24  (LR: 5.000000e-04)-----------\n",
            "loss: 0.6061050295829773\n",
            "accuracy: 0.759765625\n",
            "val loss: 0.7178414463996887\n",
            "val accuracy: 0.7186325788497925\n",
            "weight saved\n",
            "-----------epoch 25  (LR: 5.000000e-04)-----------\n",
            "loss: 0.5909718871116638\n",
            "accuracy: 0.76953125\n",
            "val loss: 0.7090359330177307\n",
            "val accuracy: 0.7163786888122559\n",
            "weight saved\n",
            "-----------epoch 26  (LR: 5.000000e-04)-----------\n",
            "loss: 0.5705968141555786\n",
            "accuracy: 0.765625\n",
            "val loss: 0.7172663807868958\n",
            "val accuracy: 0.7227648496627808\n",
            "weight saved\n",
            "-----------epoch 27  (LR: 5.000000e-04)-----------\n",
            "loss: 0.5949304103851318\n",
            "accuracy: 0.7578125\n",
            "val loss: 0.7168692946434021\n",
            "val accuracy: 0.7141247391700745\n",
            "-----------epoch 28  (LR: 5.000000e-04)-----------\n",
            "loss: 0.6428927183151245\n",
            "accuracy: 0.74609375\n",
            "val loss: 0.7243452668190002\n",
            "val accuracy: 0.7114951014518738\n",
            "-----------epoch 29  (LR: 5.000000e-04)-----------\n",
            "loss: 0.6140452027320862\n",
            "accuracy: 0.744140625\n",
            "val loss: 0.7361065149307251\n",
            "val accuracy: 0.7137490510940552\n",
            "learning rate reduced to 2.500000e-04\n",
            "-----------epoch 30  (LR: 2.500000e-04)-----------\n",
            "loss: 0.540012538433075\n",
            "accuracy: 0.798828125\n",
            "val loss: 0.7274467945098877\n",
            "val accuracy: 0.7208865284919739\n",
            "weight saved\n",
            "-----------epoch 31  (LR: 2.500000e-04)-----------\n",
            "loss: 0.5707938075065613\n",
            "accuracy: 0.779296875\n",
            "val loss: 0.7264430522918701\n",
            "val accuracy: 0.7137490510940552\n",
            "-----------epoch 32  (LR: 2.500000e-04)-----------\n",
            "loss: 0.6083176136016846\n",
            "accuracy: 0.76953125\n",
            "val loss: 0.7361974120140076\n",
            "val accuracy: 0.7122464179992676\n",
            "-----------epoch 33  (LR: 2.500000e-04)-----------\n",
            "loss: 0.5861448049545288\n",
            "accuracy: 0.767578125\n",
            "val loss: 0.7326294779777527\n",
            "val accuracy: 0.7205109000205994\n",
            "-------Early stop-------\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "epochs = 100\n",
        "batch_size = 512\n",
        "batch_count = (x_train.shape[0] // batch_size) + 1\n",
        "\n",
        "# 最小learning_rate，希望learning_rate最多下降10次\n",
        "miniLR = 0.001 / 1024\n",
        "\n",
        "# 紀錄最好的ValAccuracy\n",
        "bestValAccuracy = 0.0\n",
        "\n",
        "# 紀錄上一次的ValAccuracy\n",
        "best_val_acc = 0.0\n",
        "early_stop_count = 0\n",
        "accuracyUptime = 0\n",
        "\n",
        "def get_data(i):\n",
        "    if (i + 1) * batch_size > x_train.shape[0]:\n",
        "        x = x_train[ i * batch_size : -1]\n",
        "        y = y_train[ i * batch_size : -1]\n",
        "    else:\n",
        "        x = x_train[ (i) * batch_size : (i+1) * batch_size ]\n",
        "        y = y_train[ (i) * batch_size : (i+1) * batch_size ]\n",
        "\n",
        "    for idx, board in enumerate(x):\n",
        "        # 上下翻轉\n",
        "        if random.random() > 0.5: # 50%\n",
        "            x[idx] = cv2.flip(board, 0)\n",
        "        # 左右翻轉\n",
        "        if random.random() > 0.5: # 50%\n",
        "            x[idx] = cv2.flip(board, 1)\n",
        "    return x, y\n",
        "\n",
        "history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
        "# train\n",
        "for epoch in range(epochs):\n",
        "    print(f'-----------epoch {epoch+1}  (LR: {float(opt.learning_rate):e})-----------')\n",
        "\n",
        "    batch_sort = random.sample([i for i in range(batch_count)], batch_count)\n",
        "    for i in batch_sort:\n",
        "        X_train_batch, y_train_batch = get_data(i)\n",
        "\n",
        "        # 開始訓練\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = model(X_train_batch)\n",
        "            # Compute loss.\n",
        "            # one hot encoding用categorical_crossentropy計算loss\n",
        "            loss = tf.keras.losses.categorical_crossentropy(y_train_batch, y_pred)\n",
        "            trainable_variables = model.trainable_variables\n",
        "            # 計算梯度\n",
        "            gradients = tape.gradient(loss, trainable_variables)\n",
        "        opt.apply_gradients(zip(gradients, trainable_variables))\n",
        "\n",
        "    # 印loss和accuracy\n",
        "    print(f'loss: {sum(loss) / len(loss)}')\n",
        "    acc = tf.keras.metrics.categorical_accuracy(y_train_batch, y_pred)\n",
        "    print(f'accuracy: {sum(acc) / len(acc)}')\n",
        "\n",
        "\n",
        "    # 驗證模型\n",
        "    history[\"train_loss\"].append(sum(loss) / len(loss))\n",
        "    history[\"train_acc\"].append(sum(acc) / len(acc))\n",
        "    y_pred = model(x_val)\n",
        "    val_loss = tf.keras.losses.categorical_crossentropy(y_val, y_pred)\n",
        "    val_loss = sum(val_loss) / len(val_loss)\n",
        "    val_acc = tf.keras.metrics.categorical_accuracy(y_val, y_pred)\n",
        "    val_acc = sum(val_acc) / len(val_acc)\n",
        "\n",
        "    total_val_loss = float(val_loss)\n",
        "    total_val_acc = float(val_acc)\n",
        "    print(f'val loss: {total_val_loss}')\n",
        "    print(f'val accuracy: {total_val_acc}')\n",
        "    history[\"val_loss\"].append(total_val_loss)\n",
        "    history[\"val_acc\"].append(total_val_acc)\n",
        "\n",
        "    # draw curve\n",
        "    plt.plot(history[\"train_acc\"])\n",
        "    plt.plot(history[\"val_acc\"])\n",
        "    plt.title(\"Accuracy\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train','Val'])\n",
        "    plt.savefig(f'./accuracy.png')\n",
        "    plt.clf()\n",
        "    # draw curve\n",
        "    plt.plot(history[\"train_loss\"])\n",
        "    plt.plot(history[\"val_loss\"])\n",
        "    plt.title(\"Loss\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train','Val'])\n",
        "    plt.savefig(f'./loss.png')\n",
        "    plt.clf()\n",
        "\n",
        "    model.save_weights(f'./last.h5')\n",
        "\n",
        "    # val_accuracy比上一次好就存檔\n",
        "    if (bestValAccuracy < total_val_acc):\n",
        "        bestValAccuracy = total_val_acc\n",
        "        model.save_weights(f'./best.h5')\n",
        "        print('weight saved')\n",
        "\n",
        "    if ((epoch + 1) % 5 == 0):\n",
        "        model.save_weights(f'./epoch{epoch+1}.h5')\n",
        "        print('weight saved')\n",
        "\n",
        "    # 連續三次val_accuracy沒有上漲，learning_rate就乘1/2\n",
        "    if(best_val_acc <= total_val_acc):\n",
        "        accuracyUptime = 0\n",
        "        early_stop_count = 0\n",
        "    else:\n",
        "        accuracyUptime +=1\n",
        "        early_stop_count += 1\n",
        "        if (accuracyUptime == 3 and opt.learning_rate > miniLR):\n",
        "            opt.learning_rate = (opt.learning_rate)/2\n",
        "            print(f'learning rate reduced to {float(opt.learning_rate):e}')\n",
        "            # 下次learning rate下降是五(提高條件)\n",
        "            accuracyUptime = -2\n",
        "        if early_stop_count == 7:\n",
        "            print(\"-------Early stop-------\")\n",
        "            break\n",
        "\n",
        "    # 更新 best_val_acc\n",
        "    if total_val_acc > best_val_acc:\n",
        "        best_val_acc = total_val_acc"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
